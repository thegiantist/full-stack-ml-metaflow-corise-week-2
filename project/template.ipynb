{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Project: Refining the Art of Sentiment Analysis at ModaMetric\n",
    "\n",
    "Welcome to Week 2! The ModaMetric team is still buzzing from the achievements of last week. You've shown them the power of Metaflow and the potential of machine learning. However, there's more to explore, more to refine.\n",
    "\n",
    "Once again, weâ€™ll delve into the [Women's Ecommerce Clothing Reviews Dataset from Kaggle](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews), the dataset that helped us unlock valuable insights for ModaMetric. Your mission is to further refine the sentiment analysis process, enabling ModaMetric to better understand the sentiments embedded in the customer reviews.\n",
    "\n",
    "## Task 1: Orchestrating the Dance of Sentiment Analysis Models with Metaflow\n",
    "\n",
    "In this task, you'll utilize Metaflow to train two sentiment analysis models: the baseline \"majority class\" classifier and your own custom model. The models will be trained simultaneously, flexing the power of Metaflow. Your task also involves tweaking the models' hyperparameters for optimal performance. Finally, you'll analyze the performance of these models using Metaflow's Client API. Here's how you'll proceed:\n",
    "\n",
    "### Step 1: Constructing the Sentiment Analysis Workflows\n",
    "Your first task is to construct the Metaflow workflows. Begin with the baseline \"majority class\" classifier and then move on to your custom model. Make sure your custom model includes steps for data preprocessing, model training, and evaluation. Feel free to use techniques from Week 1 and any other [resources](https://outerbounds.com/docs/nlp-tutorial-L2/) you find useful.\n",
    "\n",
    "### Step 2: Parallel Training of Models\n",
    "Having built the models, you'll use Metaflow to train them simultaneously. The race is on - can the custom model outshine the baseline? If you find yourself in a bind, you might find the [FlowSpec branching documentation](https://docs.metaflow.org/metaflow/basics#branch) useful.\n",
    "\n",
    "### Step 3: The Hyperparameters Experiment\n",
    "Once you've trained the models, it's time for some fine-tuning. Experiment with different hyperparameters such as learning rate, batch size, and number of epochs. Record the performance of each model under different hyperparameter combinations as Data Artifacts in Metaflow.\n",
    "\n",
    "### Step 4: Results Analysis\n",
    "With the experiments complete, it's time to analyze the results. Use Metaflow's Client API to fetch the data and create visualizations to compare the models' performances. The goal is to identify the best hyperparameters for each model.\n",
    "\n",
    "By completing this task, you're not only refining the sentiment analysis process at ModaMetric but also honing your own skills in orchestrating complex machine learning workflows using Metaflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "# You can style your plots here, but it is not part of the project.\n",
    "YELLOW = \"#FFBC00\"\n",
    "GREEN = \"#37795D\"\n",
    "PURPLE = \"#5460C0\"\n",
    "BACKGROUND = \"#F4EBE6\"\n",
    "colors = [GREEN, PURPLE]\n",
    "custom_params = {\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.facecolor\": BACKGROUND,\n",
    "    \"figure.facecolor\": BACKGROUND,\n",
    "    \"figure.figsize\": (8, 8),\n",
    "}\n",
    "sns_palette = sns.color_palette(colors, len(colors))\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/workspace/workspaces/full-stack-ml-metaflow-corise-week-2/data/Womens Clothing E-Commerce Reviews.csv'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "'/home/workspace/workspaces/full-stack-ml-metaflow-corise-week-2/data/Womens Clothing E-Commerce Reviews.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labeling_function = lambda row: 1 if row['rating'] >= 4 else 0\n",
    "        \n",
    "# transformations\n",
    "df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "df = df[~df.review_text.isna()]\n",
    "df[\"review\"] = df[\"review_text\"].astype(\"str\")\n",
    "_has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "reviews = _has_review_df[\"review_text\"]\n",
    "labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "\n",
    "# split into training and validation.\n",
    "_df = pd.DataFrame({\"review\": reviews, \"label\": labels})\n",
    "traindf, valdf = train_test_split(_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22641 entries, 0 to 23485\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   label                    22641 non-null  int64 \n",
      " 1   clothing_id              22641 non-null  int64 \n",
      " 2   age                      22641 non-null  int64 \n",
      " 3   title                    19675 non-null  object\n",
      " 4   review_text              22641 non-null  object\n",
      " 5   rating                   22641 non-null  int64 \n",
      " 6   recommended_ind          22641 non-null  int64 \n",
      " 7   positive_feedback_count  22641 non-null  int64 \n",
      " 8   division_name            22628 non-null  object\n",
      " 9   department_name          22628 non-null  object\n",
      " 10  class_name               22628 non-null  object\n",
      " 11  review                   22641 non-null  object\n",
      "dtypes: int64(6), object(6)\n",
      "memory usage: 2.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended_ind</th>\n",
       "      <th>positive_feedback_count</th>\n",
       "      <th>division_name</th>\n",
       "      <th>department_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  clothing_id  age                    title  \\\n",
       "0      1          767   33                      NaN   \n",
       "1      1         1080   34                      NaN   \n",
       "2      0         1077   60  Some major design flaws   \n",
       "3      1         1049   50         My favorite buy!   \n",
       "4      1          847   47         Flattering shirt   \n",
       "\n",
       "                                         review_text  rating  recommended_ind  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   positive_feedback_count   division_name department_name class_name  \\\n",
       "0                        0       Initmates        Intimate  Intimates   \n",
       "1                        4         General         Dresses    Dresses   \n",
       "2                        0         General         Dresses    Dresses   \n",
       "3                        0  General Petite         Bottoms      Pants   \n",
       "4                        6         General            Tops    Blouses   \n",
       "\n",
       "                                              review  \n",
       "0  Absolutely wonderful - silky and sexy and comf...  \n",
       "1  Love this dress!  it's sooo pretty.  i happene...  \n",
       "2  I had such high hopes for this dress and reall...  \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...  \n",
       "4  This shirt is very flattering to all due to th...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "# Light data cleaning\n",
    "df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "df[\"review_text\"] = df[\"review_text\"].astype(\"str\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>age</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended_ind</th>\n",
       "      <th>positive_feedback_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22641.000000</td>\n",
       "      <td>22641.000000</td>\n",
       "      <td>22641.000000</td>\n",
       "      <td>22641.000000</td>\n",
       "      <td>22641.000000</td>\n",
       "      <td>22641.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.770637</td>\n",
       "      <td>919.332362</td>\n",
       "      <td>43.280376</td>\n",
       "      <td>4.183561</td>\n",
       "      <td>0.818868</td>\n",
       "      <td>2.630582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.420432</td>\n",
       "      <td>202.266874</td>\n",
       "      <td>12.326980</td>\n",
       "      <td>1.115762</td>\n",
       "      <td>0.385136</td>\n",
       "      <td>5.786164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>861.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1078.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1205.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   clothing_id           age        rating  \\\n",
       "count  22641.000000  22641.000000  22641.000000  22641.000000   \n",
       "mean       0.770637    919.332362     43.280376      4.183561   \n",
       "std        0.420432    202.266874     12.326980      1.115762   \n",
       "min        0.000000      1.000000     18.000000      1.000000   \n",
       "25%        1.000000    861.000000     34.000000      4.000000   \n",
       "50%        1.000000    936.000000     41.000000      5.000000   \n",
       "75%        1.000000   1078.000000     52.000000      5.000000   \n",
       "max        1.000000   1205.000000     99.000000      5.000000   \n",
       "\n",
       "       recommended_ind  positive_feedback_count  \n",
       "count     22641.000000             22641.000000  \n",
       "mean          0.818868                 2.630582  \n",
       "std           0.385136                 5.786164  \n",
       "min           0.000000                 0.000000  \n",
       "25%           1.000000                 0.000000  \n",
       "50%           1.000000                 1.000000  \n",
       "75%           1.000000                 3.000000  \n",
       "max           1.000000               122.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22641, 12),\n",
       " label                         0\n",
       " clothing_id                   0\n",
       " age                           0\n",
       " title                      2966\n",
       " review_text                   0\n",
       " rating                        0\n",
       " recommended_ind               0\n",
       " positive_feedback_count       0\n",
       " division_name                13\n",
       " department_name              13\n",
       " class_name                   13\n",
       " review                        0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Basic Data Summary\n",
    "\n",
    "# Shape of the dataset\n",
    "data_shape = df.shape\n",
    "\n",
    "# Summary statistics\n",
    "summary_stats = df.describe(include='all')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "data_shape, missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Labels generated and assertions passed successfully!'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def labeling_function(row):\n",
    "    \"\"\"\n",
    "    A function to derive labels from the user's review data.\n",
    "    This uses the 'rating' column to determine if a review is positive or negative.\n",
    "    Ratings of 4 or 5 are considered positive (return 1), and ratings less than 4 are considered negative (return 0).\n",
    "    \"\"\"\n",
    "    # Check the rating and return 1 for positive and 0 for negative\n",
    "    return 1 if row['rating'] >= 4 else 0\n",
    "\n",
    "# Generate labels using the labeling_function\n",
    "_has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "reviews = _has_review_df[\"review_text\"]\n",
    "labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "has_review_df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "del _has_review_df\n",
    "\n",
    "# Run provided assertions\n",
    "assert (\n",
    "    labels.shape == reviews.shape\n",
    "), \"Labels and reviews should be equal shape vectors!\"\n",
    "assert (\n",
    "    not sum([1 if r == \"nan\" else 0 for r in reviews]) > 0\n",
    "), \"There are `nan` values in the feature set!\"\n",
    "\n",
    "# Return a message indicating success\n",
    "\"Labels generated and assertions passed successfully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Positive',\n",
       "  'Just as the others have reviewed, i agree! this dress is flowy and so feminine. i got it today and i am wearing it now! so light! i usually wear a large or a 12 in dresses. i am pear shaped. 36b bust and large hips. it is flattering and feels great on. the slip underneath fits perfect on me. grab this before it becomes iso!'),\n",
       " ('Positive',\n",
       "  'This lovely cardigan is just that much more special due to the lining on the body and in the pockets. they peek out and make the sweater more interesting. i wore the black one with a lace dress with cream underlayment and the cream details on the lining worked perfectly to offset the formality of the dress and make the whole outfit casual but chic. the sweater washed in the machine and kept its shape when i hung it to dry.'),\n",
       " ('Positive',\n",
       "  'This is my favorite weekend jacket! it is so cute, soft and comfortable! the interior is an extra soft cotton that feels like my most favorite soft tee-shirt?? it is true to size. the best features are the versatility of the neck, pockets. and a little longer in the back - great over leggings/yoga pants. i ordered 2 sizes just in case the sizing was off - an xxs and xxs. i am a 2 petite and the xs is roomy enough for a sweater or sweatshirt under it. the xxs looked and felt great too and had a m'),\n",
       " ('Positive',\n",
       "  \"This is such a darling velvet dress. understated, yet eye catching, i am very fond of it. the cut is flattering to all and the gathered fabric does not add bulk to the waist. there is a fun tulle underskirt to give just the right amount of volume. the straps creep ever so slightly toward being off shoulder, but fear not because there are loops and fasteners to hold your bra in place.\\n\\ni am very thrilled to have found my holiday party dress so early and can't wait to wear it!\"),\n",
       " ('Positive',\n",
       "  'These are just some classic \"around the house\" type socks. they\\'re not comfortable enough to wear with some boots or anything. just super snuggly and soft for lounging purposes only. i love them and am contemplating buying the other pair. i got the blue and white ones to go with the farrier tee in blue and white. i\\'m kind of bummed that i can\\'t wear these anywhere but no worries. they\\'ll be great with some joggers and a sweatshirt while i work the crossword over a cup of coffee. would recommend'),\n",
       " ('Positive',\n",
       "  \"I bought the grey, which is a gorgeous color. i like the long length in the arms (though i tried it on in different colors and the arm length did very). soft and pretty. i like the length. the back does wrinkle, but i still like the shirt. it's loose, casual and flattering.\"),\n",
       " ('Positive',\n",
       "  \"This skirt is gorgeous!! drapes beautifully & the color is vibrant! get it!! you'll be so pleased! i sure am!!!\"),\n",
       " ('Positive',\n",
       "  \"I got this in a petite xs; it's gorgeous and incredibly soft, great quality as well. my one little caveat is that it's very short; i'm 5'1 with a short torso and it still didn't get very far on me, but if you wear it with high-waited pants/skirt it's not a big deal\"),\n",
       " ('Positive',\n",
       "  'I ordered the black and it was a soft black, which i loved. i felt like the shirt was a little boxy (i was hoping the top would have been a bit more fitted (the arm holes are loose) and the bottom a little longer, but i like it enough that i am keeping it. works well to wear to work.'),\n",
       " ('Positive',\n",
       "  'I just purchased this blouse in store! the fabric has a nice weight and drape, feels nice to the touch and is opaque. i\\'ll be wearing this one as a dress and a top. i\\'m 5\\'2\" and this fell a couple inches above my knee. i typically wear an xs at retailer and opted to go with a small for the extra length and because i hate when off the shoulder silhouettes pop up and become not so off the shoulder. i laid the xs and small out to compare sizing and didn\\'t notice a major  difference width wise. i typi')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch subset of data again\n",
    "idxs = np.random.choice(reviews.index, 10, replace=False)\n",
    "_labels_subset = labels[idxs]\n",
    "_reviews_subset = reviews[idxs]\n",
    "\n",
    "# Display reviews with their labels (Positive or Negative)\n",
    "review_label_pairs = []\n",
    "for label, review in zip(_labels_subset, _reviews_subset):\n",
    "    sentiment = \"Positive\" if label == 1 else \"Negative\"\n",
    "    review_label_pairs.append((sentiment, review))\n",
    "\n",
    "review_label_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/workspace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stopwords = list(nltk.corpus.stopwords.words(\"english\"))\n",
    "non_stopwords = []\n",
    "for review in reviews:\n",
    "    for word in review.split():\n",
    "        word = word.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        if word == \"\":\n",
    "            continue\n",
    "        if not word.lower() in stopwords:\n",
    "            non_stopwords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deriving the rating distribution\n",
    "rating_distribution = df['rating'].value_counts().sort_index()\n",
    "\n",
    "# Plotting the distribution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.bar(x=rating_distribution.index, height=rating_distribution.values, color=GREEN)\n",
    "ax.set_title(\"Distribution of Ratings\")\n",
    "ax.set_xlabel(\"Rating\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.064% of the labels have positive sentiment.\n"
     ]
    }
   ],
   "source": [
    "pct_positive_sentiment = labels.sum() / labels.shape[0]\n",
    "print(f\"{round(100*pct_positive_sentiment,3)}% of the labels have positive sentiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Positive',\n",
       "  'Great winter maxi. soft and comfortable fabric. good quality. stretchy but not too clingy. fitted in all the right places and very flattering. petite was unavailable so will need hemming.'),\n",
       " ('Positive',\n",
       "  'I have been eyeing this top online and initially thought it was very fitted and structured as it appears on the model. upon trying it on at the store, i agree with other reviewers it is a tad boxy. i ended up sizing down to a small and it fits nicely. (5\\' 8\", 145, usually i take a medium or 6/8 in retailer tops). i can see where this might not work for everyone, but i found it to be a fun take on a classic \"tweedy\" look. i plan to add a pop of color with jewelry or even pair it with the pin'),\n",
       " ('Positive',\n",
       "  \"I read the previous comments and was skeptical. i love the dress! it's fitted on the top and flowy on the bottom. i didn't find it too big or maternity on the bottom half. the print is really pretty with flecks of blue that brightened up the dress.\"),\n",
       " ('Positive',\n",
       "  'I love this black turtleneck. arms are a little long, so should have gotten small. i wore it and love it! you can play with collar and snaps; up or down.'),\n",
       " ('Positive',\n",
       "  \"The design of this top is super cute and the material is decent. the only flaw is that despite buying the smallest size (xxsp), it's still very boxy on me. i wish it was more fitted at the waist which would make it much more flattering. however, since i am actually pregnant, this actually works to my advantage, for the time being.\"),\n",
       " ('Positive',\n",
       "  \"The photo does not do this dress justice at all. it's a light lavender and extremely flattering. i'm athletic so have broader shoulders and hips, and this is an amazing fit for me. also, the front has a small button to make it more modest, which is closed in the photo of the model, but if you leave it open, va-va-va-voom! so, to summarize: beautiful spring lavender, fabulously feminine fit. get it!\"),\n",
       " ('Positive',\n",
       "  'These pants are amazing. they are so comfortable and fit true to size. i typically wear a 28 or 29 depending on the pants and the 28s fit me perfectly. i bought the olive green pair and they are everything i have ever wanted in a pair of olive pants. i love that they are tighter in the butt area and loose in the knees and calves so they are not restrictive. i want every color!'),\n",
       " ('Negative',\n",
       "  \"I was looking forward to trying this on after seeing it in the catalog. i wear an xs or small in retailer tops and tried this on in an xs. it was huge. reminded me of a maternity top. it was much more flowy on me than it looks on the model. the material was nice, thin but not see through. the macrame detailing seemed well made. i'd recommend this if you're looking for a flowy top but definitely size down.\"),\n",
       " ('Negative',\n",
       "  'This cute dress was very nice on. however my only reservations were the thickness in the arm sleeves. the dress has this thick curtain like material on the sleeves that seemed to big and cut way to wide for my skinny arms. i thought about bringing this to the tailor but i feel it would be a lot of work and the bulkiness of the arms would just be the same.\\n\\nother than that the colors and dress are beautiful.'),\n",
       " ('Negative',\n",
       "  'The cowl and cuffs of the dress are thick and heavy sweater material, but the dress itself is extremely thin. the non-belted pictures do not show how much volume there is to the dress, which was enormous in my normal size.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch subset of data again\n",
    "idxs = np.random.choice(reviews.index, 10, replace=False)\n",
    "_labels_subset = labels[idxs]\n",
    "_reviews_subset = reviews[idxs]\n",
    "\n",
    "# Display reviews with their labels (Positive or Negative)\n",
    "review_label_pairs = []\n",
    "for label, review in zip(_labels_subset, _reviews_subset):\n",
    "    sentiment = \"Positive\" if label == 1 else \"Negative\"\n",
    "    review_label_pairs.append((sentiment, review))\n",
    "\n",
    "review_label_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>clothing_id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended_ind</th>\n",
       "      <th>positive_feedback_count</th>\n",
       "      <th>division_name</th>\n",
       "      <th>department_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  clothing_id  age                    title  \\\n",
       "0      1          767   33                      NaN   \n",
       "1      1         1080   34                      NaN   \n",
       "2      0         1077   60  Some major design flaws   \n",
       "3      1         1049   50         My favorite buy!   \n",
       "4      1          847   47         Flattering shirt   \n",
       "\n",
       "                                         review_text  rating  recommended_ind  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   positive_feedback_count   division_name department_name class_name  \\\n",
       "0                        0       Initmates        Intimate  Intimates   \n",
       "1                        4         General         Dresses    Dresses   \n",
       "2                        0         General         Dresses    Dresses   \n",
       "3                        0  General Petite         Bottoms      Pants   \n",
       "4                        6         General            Tops    Blouses   \n",
       "\n",
       "                                              review  \n",
       "0  Absolutely wonderful - silky and sexy and comf...  \n",
       "1  Love this dress!  it's sooo pretty.  i happene...  \n",
       "2  I had such high hopes for this dress and reall...  \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...  \n",
       "4  This shirt is very flattering to all due to th...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17448\n",
       "0     5193\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class: 1\n",
      "Majority Class Baseline Accuracy: 0.7781\n"
     ]
    }
   ],
   "source": [
    "# TODO: build the majority class baseline model.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TODO: find the majority class in the labels. ðŸ¤”\n",
    "majority_class = traindf['label'].mode()[0]\n",
    "print(f'majority class: {majority_class}')\n",
    "baseline_predictions = [majority_class] * len(valdf)\n",
    "\n",
    "# TODO: score the model on valdf with a 2D metric space: sklearn.metrics.accuracy_score, sklearn.metrics.roc_auc_score\n",
    "# Documentation on suggested model-scoring approach: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "baseline_accuracy = accuracy_score(valdf['label'], baseline_predictions)\n",
    "print(f\"Majority Class Baseline Accuracy: {baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "# TODO: modify this custom model to your liking. Check out this tutorial for more on this class: https://outerbounds.com/docs/nlp-tutorial-L2/\n",
    "# TODO: train the model on traindf.\n",
    "# TODO: score the model on valdf with _the same_ 2D metric space you used in previous cell.\n",
    "# TODO: test your model works by importing the model module in notebook cells, and trying to fit traindf and score predictions on the valdf data!\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, regularizers\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "class NbowModel:\n",
    "    def __init__(self, vocab_sz):\n",
    "        self.vocab_sz = vocab_sz\n",
    "\n",
    "        # Instantiate the CountVectorizer\n",
    "        self.cv = CountVectorizer(\n",
    "            min_df=0.005,\n",
    "            max_df=0.75,\n",
    "            stop_words=\"english\",\n",
    "            strip_accents=\"ascii\",\n",
    "            max_features=self.vocab_sz,\n",
    "        )\n",
    "\n",
    "        # Define the keras model\n",
    "        inputs = tf.keras.Input(shape=(self.vocab_sz,), name=\"input\")\n",
    "        x = layers.Dropout(0.10)(inputs)\n",
    "        x = layers.Dense(\n",
    "            15,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "        )(x)\n",
    "        predictions = layers.Dense(\n",
    "            1,\n",
    "            activation=\"sigmoid\",\n",
    "        )(x)\n",
    "        self.model = tf.keras.Model(inputs, predictions)\n",
    "        opt = optimizers.Adam(learning_rate=0.002)\n",
    "        self.model.compile(\n",
    "            loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print(X.shape)\n",
    "        print(X[0])\n",
    "        res = self.cv.fit_transform(X).toarray()\n",
    "        self.model.fit(x=res, y=y, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(X.shape)\n",
    "        print(X[0])\n",
    "        res = self.cv.transform(X).toarray()\n",
    "        return self.model.predict(res)\n",
    "\n",
    "    def eval_acc(self, X, labels, threshold=0.5):\n",
    "        return accuracy_score(labels, self.predict(X) > threshold)\n",
    "\n",
    "    def eval_rocauc(self, X, labels):\n",
    "        return roc_auc_score(labels, self.predict(X))\n",
    "\n",
    "    @property\n",
    "    def model_dict(self):\n",
    "        return {\"vectorizer\": self.cv, \"model\": self.model}\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, model_dict):\n",
    "        \"Get Model from dictionary\"\n",
    "        nbow_model = cls(len(model_dict[\"vectorizer\"].vocabulary_))\n",
    "        nbow_model.model = model_dict[\"model\"]\n",
    "        nbow_model.cv = model_dict[\"vectorizer\"]\n",
    "        return nbow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 17:41:41.260046: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-30 17:41:59.049848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18112,)\n",
      "I ordered the top from a store to have it shipped.\n",
      "it is very pretty but once on, it fit the wrong way. i got a small because i know that this designer tends to run tight across the bust.\n",
      "the shoulder was too rounded for this neck line. sleeves should have been either longer or sleeveless. the empire waist even on a smaller busted woman like myself was cut too high.\n",
      "Epoch 1/10\n",
      "453/453 [==============================] - 2s 3ms/step - loss: 0.4007 - accuracy: 0.8253 - val_loss: 0.3459 - val_accuracy: 0.8551\n",
      "Epoch 2/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3386 - accuracy: 0.8551 - val_loss: 0.3394 - val_accuracy: 0.8545\n",
      "Epoch 3/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8618 - val_loss: 0.3389 - val_accuracy: 0.8567\n",
      "Epoch 4/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3194 - accuracy: 0.8690 - val_loss: 0.3376 - val_accuracy: 0.8576\n",
      "Epoch 5/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.8686 - val_loss: 0.3452 - val_accuracy: 0.8543\n",
      "Epoch 6/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3055 - accuracy: 0.8749 - val_loss: 0.3466 - val_accuracy: 0.8540\n",
      "Epoch 7/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2993 - accuracy: 0.8769 - val_loss: 0.3483 - val_accuracy: 0.8551\n",
      "Epoch 8/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2900 - accuracy: 0.8834 - val_loss: 0.3531 - val_accuracy: 0.8532\n",
      "Epoch 9/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.8886 - val_loss: 0.3602 - val_accuracy: 0.8482\n",
      "Epoch 10/10\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2784 - accuracy: 0.8934 - val_loss: 0.3671 - val_accuracy: 0.8468\n",
      "(4529,)\n",
      "I ordered the coral, size small, it's a beautiful peach color and the linen is very soft. it is longer, and roomier in the waist than i was expecting, however, with skinny jeans it looks great. the detail makes this top very eye-catching, i'm very happy with my purchase!\n",
      "142/142 [==============================] - 0s 933us/step\n",
      "(4529,)\n",
      "I ordered the coral, size small, it's a beautiful peach color and the linen is very soft. it is longer, and roomier in the waist than i was expecting, however, with skinny jeans it looks great. the detail makes this top very eye-catching, i'm very happy with my purchase!\n",
      "142/142 [==============================] - 0s 958us/step\n",
      "Validation Accuracy: 0.8578\n",
      "Validation ROC AUC Score: 0.8981\n"
     ]
    }
   ],
   "source": [
    "from model import NbowModel\n",
    "\n",
    "# Train the model\n",
    "nbow = NbowModel(vocab_sz=500)  \n",
    "nbow.fit(traindf['review'].values, traindf['label'].values)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = nbow.eval_acc(valdf['review'].values, valdf['label'].values)\n",
    "rocauc = nbow.eval_rocauc(valdf['review'].values, valdf['label'].values)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation ROC AUC Score: {rocauc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing baseline_challenge.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile baseline_challenge.py\n",
    "# TODO: In this cell, write your BaselineChallenge flow in the baseline_challenge.py file.\n",
    "\n",
    "from metaflow import (\n",
    "    FlowSpec,\n",
    "    step,\n",
    "    Flow,\n",
    "    current,\n",
    "    Parameter,\n",
    "    IncludeFile,\n",
    "    card,\n",
    "    current,\n",
    ")\n",
    "from metaflow.cards import Table, Markdown, Artifact, Image\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# TODO: Define your labeling function here.\n",
    "labeling_function = lambda row: 1 if row['rating'] >= 4 else 0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelResult:\n",
    "    \"A custom struct for storing model evaluation results.\"\n",
    "    name: None\n",
    "    params: None\n",
    "    pathspec: None\n",
    "    acc: None\n",
    "    rocauc: None\n",
    "\n",
    "\n",
    "class BaselineChallenge(FlowSpec):\n",
    "    split_size = Parameter(\"split-sz\", default=0.2)\n",
    "    data = IncludeFile(\"data\", default=\"Womens Clothing E-Commerce Reviews.csv\")\n",
    "    kfold = Parameter(\"k\", default=5)\n",
    "    scoring = Parameter(\"scoring\", default=\"accuracy\")\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # load dataset packaged with the flow.\n",
    "        # this technique is convenient when working with small datasets that need to move to remove tasks.\n",
    "        # TODO: load the data.\n",
    "        df = pd.read_csv(io.BytesIO(self.data), index_col=0) # since it was loaded as an IncludeFile it is byte-like\n",
    "\n",
    "        # Look up a few lines to the IncludeFile('data', default='Womens Clothing E-Commerce Reviews.csv').\n",
    "        # You can find documentation on IncludeFile here: https://docs.metaflow.org/scaling/data#data-in-local-files\n",
    "\n",
    "        # filter down to reviews and labels\n",
    "        df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "        df = df[~df.review_text.isna()]\n",
    "        df[\"review\"] = df[\"review_text\"].astype(\"str\")\n",
    "        _has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "        reviews = _has_review_df[\"review_text\"]\n",
    "        labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "        self.df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "\n",
    "        # split the data 80/20, or by using the flow's split-sz CLI argument\n",
    "        _df = pd.DataFrame({\"review\": reviews, \"label\": labels})\n",
    "        self.traindf, self.valdf = train_test_split(_df, test_size=self.split_size)\n",
    "        print(f\"num of rows in train set: {self.traindf.shape[0]}\")\n",
    "        print(f\"num of rows in validation set: {self.valdf.shape[0]}\")\n",
    "\n",
    "        self.next(self.baseline, self.model)\n",
    "\n",
    "    @step\n",
    "    def baseline(self):\n",
    "        \"Compute the baseline\"\n",
    "\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "        self._name = \"baseline\"\n",
    "        params = \"Always predict 1\"\n",
    "        pathspec = f\"{current.flow_name}/{current.run_id}/{current.step_name}/{current.task_id}\"\n",
    "\n",
    "        # TODO: predict the majority class\n",
    "        predictions = [1] * len(self.valdf)  # Since your majority class is 1\n",
    "\n",
    "        # TODO: return the accuracy_score of these predictions\n",
    "        acc = accuracy_score(self.valdf['label'].values, predictions)\n",
    "\n",
    "        # TODO: return the roc_auc_score of these predictions\n",
    "        rocauc = roc_auc_score(self.valdf['label'].values, predictions)\n",
    "\n",
    "\n",
    "        self.result = ModelResult(\"Baseline\", params, pathspec, acc, rocauc)\n",
    "        self.next(self.aggregate)\n",
    "\n",
    "    @step\n",
    "    def model(self):\n",
    "        # TODO: import your model if it is defined in another file.\n",
    "        from project.model import NbowModel\n",
    "\n",
    "        self._name = \"model\"\n",
    "        # NOTE: If you followed the link above to find a custom model implementation,\n",
    "        # you will have noticed your model's vocab_sz hyperparameter.\n",
    "        # Too big of vocab_sz causes an error. Can you explain why?\n",
    "        self.hyperparam_set = [{\"vocab_sz\": 100}, {\"vocab_sz\": 300}, {\"vocab_sz\": 500}]\n",
    "        pathspec = f\"{current.flow_name}/{current.run_id}/{current.step_name}/{current.task_id}\"\n",
    "\n",
    "        self.results = []\n",
    "        for params in self.hyperparam_set:\n",
    "            model = NbowModel(vocab_sz=params['vocab_sz'])  # TODO: instantiate your custom model here!\n",
    "            model.fit(X=self.traindf[\"review\"].values, y=self.traindf[\"label\"].values)\n",
    "\n",
    "            model.fit(X=self.df[\"review\"], y=self.df[\"label\"])\n",
    "            # TODO: evaluate your custom model in an equivalent way to accuracy_score.\n",
    "            acc = model.eval_acc(self.valdf[\"review\"].values, self.valdf[\"label\"].values)\n",
    "            # TODO: evaluate your custom model in an equivalent way to roc_auc_score.\n",
    "            rocauc = model.eval_rocauc(self.valdf[\"review\"].values, self.valdf[\"label\"].values)\n",
    "            self.results.append(\n",
    "                ModelResult(\n",
    "                    f\"NbowModel - vocab_sz: {params['vocab_sz']}\",\n",
    "                    params,\n",
    "                    pathspec,\n",
    "                    acc,\n",
    "                    rocauc,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.next(self.aggregate)\n",
    "\n",
    "    @step\n",
    "    def aggregate(self):\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BaselineChallenge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Mastering the Art of Anticipation: Failures and Remedies in ModaMetric's Machine Learning Journey\n",
    "\n",
    "In this task, your challenge is to step into the role of a foresightful data scientist at ModaMetric, where you'll be anticipating potential pitfalls in the sentiment analysis classifier project. Not just that, but you'll also be charting out strategies to steer clear of these hitches. Here's how you'll navigate through:\n",
    "\n",
    "### Step 1: Forecasting Potential Failure Modes\n",
    "\n",
    "The key to overcoming challenges is to anticipate them. Start by picturing possible failure scenarios from an engineering perspective. For instance, you might think about problems like overfitting to the training data or biases in the data. Remember, the first step to finding a solution is acknowledging the problem.\n",
    "\n",
    "### Step 2: Strategizing to Mitigate Failure Modes\n",
    "\n",
    "Having identified the potential obstacles, your next task is to devise counter-strategies. Consider what steps you'd take to address the problem if it arises. For instance, to counter overfitting, you could employ regularization techniques such as L1 or L2 regularization. Think of this step as drawing up a contingency plan.\n",
    "\n",
    "### Step 3: Planning Ahead to Dodge Failure Modes\n",
    "\n",
    "Beyond reactive strategies, you also need a proactive plan. What could you have done at the outset to avoid these potential pitfalls? Could you have collected a more diverse dataset to reduce bias? Or experimented with different model architectures? The goal is to minimize reactive measures and maximize foresight.\n",
    "\n",
    "This task emphasizes the importance of anticipation in machine learning projects. By identifying possible failure modes and crafting mitigation strategies, you'll be preparing yourself for a smooth-sailing machine learning journey at ModaMetric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Bringing ML Results to Life: ModaMetric's Visualization Adventure with MF Cards\n",
    "\n",
    "It's time for you to go beyond the code and transform data into a visual narrative. As a member of ModaMetric's data science team, your next mission is to enhance the existing flow in your `baseline_challenge.py` file. Add a new layer that gathers the results from all the hyperparameter tuning jobs. But that's not all - you're also going to breathe life into this aggregated data by creating a data visualization using Metaflow cards. Here's what you need to do:\n",
    "\n",
    "### Step 1: Extend Your Flow\n",
    "\n",
    "Your first challenge is to add another level to your existing `baseline_challenge.py` file. This new addition should be able to collate all the outcomes from your various hyperparameter tuning jobs. \n",
    "\n",
    "### Step 2: Log Results and Create Data Visualization\n",
    "\n",
    "Once you've collected the outcomes, it's time to log the results in a structured way. Then, you're going to take this information and create a compelling data visualization using Metaflow cards. Remember, a picture is worth a thousand numbers. With these visual insights, you'll be enabling ModaMetric to understand the performance of your machine learning model in a glance.\n",
    "\n",
    "This task is your opportunity to blend your technical skills with creative thinking. By visualizing your ML results, you're not only making the data more digestible but also contributing to ModaMetric's data-driven decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting baseline_challenge.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile baseline_challenge.py\n",
    "# TODO: In this cell, write your BaselineChallenge flow in the baseline_challenge.py file.\n",
    "\n",
    "from metaflow import (\n",
    "    FlowSpec,\n",
    "    step,\n",
    "    Flow,\n",
    "    current,\n",
    "    Parameter,\n",
    "    IncludeFile,\n",
    "    card,\n",
    "    current,\n",
    ")\n",
    "from metaflow.cards import Table, Markdown, Artifact, Image\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# TODO: Define your labeling function here.\n",
    "labeling_function = lambda row: 1 if row['rating'] >= 4 else 0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelResult:\n",
    "    \"A custom struct for storing model evaluation results.\"\n",
    "    name: None\n",
    "    params: None\n",
    "    pathspec: None\n",
    "    acc: None\n",
    "    rocauc: None\n",
    "\n",
    "class BaselineChallenge(FlowSpec):\n",
    "    split_size = Parameter(\"split-sz\", default=0.2)\n",
    "    data = IncludeFile(\"data\", default='../data/Womens Clothing E-Commerce Reviews.csv')\n",
    "    kfold = Parameter(\"k\", default=5)\n",
    "    scoring = Parameter(\"scoring\", default=\"accuracy\")\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        import pandas as pd\n",
    "        import io\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # load dataset packaged with the flow.\n",
    "        # this technique is convenient when working with small datasets that need to move to remove tasks.\n",
    "        # TODO: load the data.\n",
    "        # df = pd.read_csv(io.BytesIO(self.data), index_col=0) # since it was loaded as an IncludeFile it is byte-like\n",
    "        df=self.data\n",
    "        df = pd.read_csv('../data/Womens Clothing E-Commerce Reviews.csv',index_col=0 )\n",
    "        print(df.head())\n",
    "        # Look up a few lines to the IncludeFile('data', default='Womens Clothing E-Commerce Reviews.csv').\n",
    "        # You can find documentation on IncludeFile here: https://docs.metaflow.org/scaling/data#data-in-local-files\n",
    "\n",
    "        # filter down to reviews and labels\n",
    "        df.columns = [\"_\".join(name.lower().strip().split()) for name in df.columns]\n",
    "        df = df[~df.review_text.isna()]\n",
    "        df[\"review\"] = df[\"review_text\"].astype(\"str\")\n",
    "        _has_review_df = df[df[\"review_text\"] != \"nan\"]\n",
    "        reviews = _has_review_df[\"review_text\"]\n",
    "        labels = _has_review_df.apply(labeling_function, axis=1)\n",
    "        self.df = pd.DataFrame({\"label\": labels, **_has_review_df})\n",
    "\n",
    "        # split the data 80/20, or by using the flow's split-sz CLI argument\n",
    "        _df = pd.DataFrame({\"review\": reviews, \"label\": labels})\n",
    "        self.traindf, self.valdf = train_test_split(_df, test_size=self.split_size)\n",
    "        print(f\"num of rows in train set: {self.traindf.shape[0]}\")\n",
    "        print(f\"num of rows in validation set: {self.valdf.shape[0]}\")\n",
    "\n",
    "        self.next(self.baseline, self.model)\n",
    "\n",
    "\n",
    "    @step\n",
    "    def baseline(self):\n",
    "        \"Compute the baseline\"\n",
    "\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "        self._name = \"baseline\"\n",
    "        params = \"Always predict 1\"\n",
    "        pathspec = f\"{current.flow_name}/{current.run_id}/{current.step_name}/{current.task_id}\"\n",
    "\n",
    "        # TODO: predict the majority class\n",
    "\n",
    "        predictions = [1] * len(self.valdf)  # Since your majority class is 1\n",
    "\n",
    "        # TODO: return the accuracy_score of these predictions\n",
    "        acc = accuracy_score(self.valdf['label'].values, predictions)\n",
    "\n",
    "        # TODO: return the roc_auc_score of these predictions\n",
    "        rocauc = roc_auc_score(self.valdf['label'].values, predictions)\n",
    "\n",
    "\n",
    "        self.result = ModelResult(\"Baseline\", params, pathspec, acc, rocauc)\n",
    "        self.next(self.aggregate)\n",
    "\n",
    "\n",
    "    @step\n",
    "    def model(self):\n",
    "        # TODO: import your model if it is defined in another file.\n",
    "        from model import NbowModel\n",
    "\n",
    "        self._name = \"model\"\n",
    "        # NOTE: If you followed the link above to find a custom model implementation,\n",
    "        # you will have noticed your model's vocab_sz hyperparameter.\n",
    "        # Too big of vocab_sz causes an error. Can you explain why?\n",
    "        self.hyperparam_set = [{\"vocab_sz\": 100}, {\"vocab_sz\": 300}, {\"vocab_sz\": 500}]\n",
    "        pathspec = f\"{current.flow_name}/{current.run_id}/{current.step_name}/{current.task_id}\"\n",
    "\n",
    "        self.results = []\n",
    "        for params in self.hyperparam_set:\n",
    "            model = NbowModel(vocab_sz=params['vocab_sz'])  # TODO: instantiate your custom model here!\n",
    "            model.fit(X=self.traindf[\"review\"].values, y=self.traindf[\"label\"].values)\n",
    "\n",
    "            model.fit(X=self.df[\"review\"], y=self.df[\"label\"])\n",
    "            # TODO: evaluate your custom model in an equivalent way to accuracy_score.\n",
    "            acc = model.eval_acc(self.valdf[\"review\"].values, self.valdf[\"label\"].values)\n",
    "            # TODO: evaluate your custom model in an equivalent way to roc_auc_score.\n",
    "            rocauc = model.eval_rocauc(self.valdf[\"review\"].values, self.valdf[\"label\"].values)\n",
    "            self.results.append(\n",
    "                ModelResult(\n",
    "                    f\"NbowModel - vocab_sz: {params['vocab_sz']}\",\n",
    "                    params,\n",
    "                    pathspec,\n",
    "                    acc,\n",
    "                    rocauc,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.next(self.aggregate)\n",
    "\n",
    "\n",
    "    def add_one(self, rows, result, df):\n",
    "        \"A helper function to load results.\"\n",
    "        rows.append(\n",
    "            [\n",
    "                Markdown(result.name),\n",
    "                Artifact(result.params),\n",
    "                Artifact(result.pathspec),\n",
    "                Artifact(result.acc),\n",
    "                Artifact(result.rocauc),\n",
    "            ]\n",
    "        )\n",
    "        df[\"name\"].append(result.name)\n",
    "        df[\"accuracy\"].append(result.acc)\n",
    "        return rows, df\n",
    "\n",
    "    @card(type=\"corise\")  # TODO: Set your card type to \"corise\".\n",
    "    # I wonder what other card types there are?\n",
    "    # https://docs.metaflow.org/metaflow/visualizing-results\n",
    "    # https://github.com/outerbounds/metaflow-card-altair/blob/main/altairflow.py\n",
    "    @step\n",
    "    def aggregate(self, inputs):\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib import rcParams\n",
    "        import pandas as pd\n",
    "\n",
    "        rcParams.update({\"figure.autolayout\": True})\n",
    "\n",
    "        rows = []\n",
    "        violin_plot_df = {\"name\": [], \"accuracy\": []}\n",
    "        for task in inputs:\n",
    "            if task._name == \"model\":\n",
    "                for result in task.results:\n",
    "                    print(result)\n",
    "                    rows, violin_plot_df = self.add_one(rows, result, violin_plot_df)\n",
    "            elif task._name == \"baseline\":\n",
    "                print(task.result)\n",
    "                rows, violin_plot_df = self.add_one(rows, task.result, violin_plot_df)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown task._name type. Cannot parse results.\")\n",
    "\n",
    "        current.card.append(Markdown(\"# All models from this flow run\"))\n",
    "\n",
    "        # TODO: Add a Table of the results to your card!\n",
    "        current.card.append(\n",
    "            Table.from_dataframe(\n",
    "                pd.DataFrame(violin_plot_df,  # TODO: What goes here to populate the Table in the card?\n",
    "                # columns=[\"Model name\", \"Params\", \"Task pathspec\", \"Accuracy\", \"ROCAUC\"],\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        plt.xticks(rotation=40)\n",
    "        sns.violinplot(data=violin_plot_df, x=\"name\", y=\"accuracy\", ax=ax)\n",
    "\n",
    "        # TODO: Append the matplotlib fig to the card\n",
    "        # Docs: https://docs.metaflow.org/metaflow/visualizing-results/easy-custom-reports-with-card-components#showing-plots\n",
    "        current.card.append(Image.from_matplotlib(fig))\n",
    "\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BaselineChallenge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.9.7.2+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mBaselineChallenge\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[22mIncluding file ../data/Womens Clothing E-Commerce Reviews.csv of size 8MB \u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:44.767 \u001b[0m\u001b[1mWorkflow starting (run-id 9), see it in the UI at https://ui-pw-1791674716.outerbounds.dev/BaselineChallenge/9\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:44.995 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:48.339 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[22mClothing ID  Age  ... Department Name Class Name\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:48.665 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[22m0          767   33  ...        Intimate  Intimates\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:48.665 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[22m1         1080   34  ...         Dresses    Dresses\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:48.665 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[22m2         1077   60  ...         Dresses    Dresses\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:48.665 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[22m3         1049   50  ...         Bottoms      Pants\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:48.666 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[22m4          847   47  ...            Tops    Blouses\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:48.666 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:48.666 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[22m[5 rows x 10 columns]\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:48.666 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[22mnum of rows in train set: 18112\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:52.427 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[22mnum of rows in validation set: 4529\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:52.742 \u001b[0m\u001b[32m[9/start/70 (pid 9620)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:53.129 \u001b[0m\u001b[32m[9/baseline/71 (pid 9731)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:53.299 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:55.439 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m2023-10-30 17:45:55.439074: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:59.532 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:59.533 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m2023-10-30 17:45:59.532769: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[0m\n",
      "\u001b[35m2023-10-30 17:45:59.748 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(18112,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:01.122 \u001b[0m\u001b[32m[9/baseline/71 (pid 9731)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:01.291 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mThis dress is lovely. the embroidery is beautifully done and with bright colors. the material is sturdy. the fit is overall true to size but slightly small through the bust. the length is several inches above my knees and i ordered the 6 regular even though i am only 5'4\". the pockets are a bonus!\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:01.291 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "453/453 [==============================] - 2s 2ms/step - loss: 0.4670 - accuracy: 0.7859 - val_loss: 0.4084 - val_accuracy: 0.8242\u001b[0m85 - accuracy: 0.53\n",
      "\u001b[35m2023-10-30 17:46:02.372 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.4261 - accuracy: 0.8056 - val_loss: 0.4040 - val_accuracy: 0.8236\u001b[0m - accuracy: 0.68\n",
      "\u001b[35m2023-10-30 17:46:03.167 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.4187 - accuracy: 0.8128 - val_loss: 0.4051 - val_accuracy: 0.8231\u001b[0m - accuracy: 0.81\n",
      "\u001b[35m2023-10-30 17:46:03.938 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.4161 - accuracy: 0.8138 - val_loss: 0.4009 - val_accuracy: 0.8297\u001b[0m - accuracy: 0.81\n",
      "\u001b[35m2023-10-30 17:46:04.765 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.4127 - accuracy: 0.8148 - val_loss: 0.3994 - val_accuracy: 0.8245\u001b[0m - accuracy: 0.78\n",
      "\u001b[35m2023-10-30 17:46:05.589 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8190 - val_loss: 0.4034 - val_accuracy: 0.8256\u001b[0m - accuracy: 0.84\n",
      "\u001b[35m2023-10-30 17:46:06.349 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.4073 - accuracy: 0.8205 - val_loss: 0.4010 - val_accuracy: 0.8228\u001b[0m - accuracy: 0.84\n",
      "\u001b[35m2023-10-30 17:46:07.123 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.4050 - accuracy: 0.8197 - val_loss: 0.4058 - val_accuracy: 0.8220\u001b[0m - accuracy: 0.81\n",
      "\u001b[35m2023-10-30 17:46:07.931 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8247 - val_loss: 0.4009 - val_accuracy: 0.8267\u001b[0m - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:46:08.766 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3993 - accuracy: 0.8267 - val_loss: 0.4031 - val_accuracy: 0.8247\u001b[0m - accuracy: 0.81\n",
      "\u001b[35m2023-10-30 17:46:09.843 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(22641,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:09.843 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mAbsolutely wonderful - silky and sexy and comfortable\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:11.106 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "566/566 [==============================] - 2s 3ms/step - loss: 0.4149 - accuracy: 0.8116 - val_loss: 0.3965 - val_accuracy: 0.8309\u001b[0m08 - accuracy: 0.71\n",
      "\u001b[35m2023-10-30 17:46:13.313 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4070 - accuracy: 0.8203 - val_loss: 0.4001 - val_accuracy: 0.8287\u001b[0m - accuracy: 0.81\n",
      "\u001b[35m2023-10-30 17:46:14.505 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8221 - val_loss: 0.4017 - val_accuracy: 0.8220\u001b[0m - accuracy: 0.78\n",
      "\u001b[35m2023-10-30 17:46:15.733 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8245 - val_loss: 0.4022 - val_accuracy: 0.8234\u001b[0m - accuracy: 0.81\n",
      "\u001b[35m2023-10-30 17:46:17.013 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3983 - accuracy: 0.8253 - val_loss: 0.4054 - val_accuracy: 0.8236\u001b[0m - accuracy: 0.68\n",
      "\u001b[35m2023-10-30 17:46:18.260 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3967 - accuracy: 0.8253 - val_loss: 0.4060 - val_accuracy: 0.8247\u001b[0m - accuracy: 0.84\n",
      "\u001b[35m2023-10-30 17:46:19.450 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3931 - accuracy: 0.8269 - val_loss: 0.4101 - val_accuracy: 0.8225\u001b[0m - accuracy: 0.84\n",
      "\u001b[35m2023-10-30 17:46:20.682 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3955 - accuracy: 0.8260 - val_loss: 0.4112 - val_accuracy: 0.8205\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:46:21.853 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3921 - accuracy: 0.8270 - val_loss: 0.4086 - val_accuracy: 0.8236\u001b[0m - accuracy: 0.84\n",
      "\u001b[35m2023-10-30 17:46:23.066 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3918 - accuracy: 0.8273 - val_loss: 0.4130 - val_accuracy: 0.8214\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:46:24.417 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(4529,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:24.776 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mI received these pants today and they're perfect. as another reviewer stated, \"i would definitely not wear these for lounging\" you can dress them up or down. i feel like these will be my favorite go-to pants this spring. i highly recommend the design and pockets are perfect\u001b[0m\n",
      "142/142 [==============================] - 0s 852us/step\u001b[0m] \u001b[0m\u001b[22m1/142 [..............................] - ETA: 11\n",
      "\u001b[35m2023-10-30 17:46:24.970 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(4529,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:25.250 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mI received these pants today and they're perfect. as another reviewer stated, \"i would definitely not wear these for lounging\" you can dress them up or down. i feel like these will be my favorite go-to pants this spring. i highly recommend the design and pockets are perfect\u001b[0m\n",
      "142/142 [==============================] - 0s 975us/step\u001b[0m] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "\u001b[35m2023-10-30 17:46:25.473 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(18112,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:26.506 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mThis dress is lovely. the embroidery is beautifully done and with bright colors. the material is sturdy. the fit is overall true to size but slightly small through the bust. the length is several inches above my knees and i ordered the 6 regular even though i am only 5'4\". the pockets are a bonus!\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:26.506 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "453/453 [==============================] - 2s 2ms/step - loss: 0.4206 - accuracy: 0.8097 - val_loss: 0.3464 - val_accuracy: 0.8562\u001b[0m29 - accuracy: 0.50\n",
      "\u001b[35m2023-10-30 17:46:28.047 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3576 - accuracy: 0.8494 - val_loss: 0.3375 - val_accuracy: 0.8595\u001b[0m - accuracy: 0.81\n",
      "\u001b[35m2023-10-30 17:46:28.960 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8522 - val_loss: 0.3376 - val_accuracy: 0.8579\u001b[0m - accuracy: 0.93\n",
      "\u001b[35m2023-10-30 17:46:29.844 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8567 - val_loss: 0.3367 - val_accuracy: 0.8603\u001b[0m - accuracy: 0.96\n",
      "\u001b[35m2023-10-30 17:46:30.741 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8624 - val_loss: 0.3344 - val_accuracy: 0.8631\u001b[0m - accuracy: 0.84\n",
      "\u001b[35m2023-10-30 17:46:31.608 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8661 - val_loss: 0.3364 - val_accuracy: 0.8595\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:46:32.460 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3228 - accuracy: 0.8664 - val_loss: 0.3382 - val_accuracy: 0.8614\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:46:33.308 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.8736 - val_loss: 0.3402 - val_accuracy: 0.8661\u001b[0m - accuracy: 0.84\n",
      "\u001b[35m2023-10-30 17:46:34.156 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3092 - accuracy: 0.8755 - val_loss: 0.3467 - val_accuracy: 0.8595\u001b[0m - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:46:35.006 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3073 - accuracy: 0.8776 - val_loss: 0.3506 - val_accuracy: 0.8573\u001b[0m - accuracy: 0.93\n",
      "\u001b[35m2023-10-30 17:46:35.856 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(22641,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:37.146 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mAbsolutely wonderful - silky and sexy and comfortable\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:37.146 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "566/566 [==============================] - 2s 3ms/step - loss: 0.3427 - accuracy: 0.8580 - val_loss: 0.3183 - val_accuracy: 0.8759\u001b[0m38 - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:46:39.425 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8696 - val_loss: 0.3287 - val_accuracy: 0.8706\u001b[0m - accuracy: 0.84\n",
      "\u001b[35m2023-10-30 17:46:40.711 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3156 - accuracy: 0.8720 - val_loss: 0.3347 - val_accuracy: 0.8644\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:46:41.956 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3078 - accuracy: 0.8762 - val_loss: 0.3369 - val_accuracy: 0.8651\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:46:43.221 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8785 - val_loss: 0.3403 - val_accuracy: 0.8673\u001b[0m - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:46:44.464 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3033 - accuracy: 0.8770 - val_loss: 0.3464 - val_accuracy: 0.8600\u001b[0m - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:46:45.691 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2969 - accuracy: 0.8817 - val_loss: 0.3493 - val_accuracy: 0.8638\u001b[0m - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:46:46.961 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.8850 - val_loss: 0.3588 - val_accuracy: 0.8563\u001b[0m - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:46:48.228 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2931 - accuracy: 0.8837 - val_loss: 0.3661 - val_accuracy: 0.8554\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:46:49.513 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2869 - accuracy: 0.8866 - val_loss: 0.3695 - val_accuracy: 0.8569\u001b[0m - accuracy: 0.93\n",
      "\u001b[35m2023-10-30 17:46:50.823 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(4529,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:51.147 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mI received these pants today and they're perfect. as another reviewer stated, \"i would definitely not wear these for lounging\" you can dress them up or down. i feel like these will be my favorite go-to pants this spring. i highly recommend the design and pockets are perfect\u001b[0m\n",
      "142/142 [==============================] - 0s 937us/step\u001b[0m] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "\u001b[35m2023-10-30 17:46:51.332 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(4529,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:51.620 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mI received these pants today and they're perfect. as another reviewer stated, \"i would definitely not wear these for lounging\" you can dress them up or down. i feel like these will be my favorite go-to pants this spring. i highly recommend the design and pockets are perfect\u001b[0m\n",
      "142/142 [==============================] - 0s 863us/step\u001b[0m] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "\u001b[35m2023-10-30 17:46:51.831 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(18112,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:53.069 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mThis dress is lovely. the embroidery is beautifully done and with bright colors. the material is sturdy. the fit is overall true to size but slightly small through the bust. the length is several inches above my knees and i ordered the 6 regular even though i am only 5'4\". the pockets are a bonus!\u001b[0m\n",
      "\u001b[35m2023-10-30 17:46:53.069 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "453/453 [==============================] - 2s 2ms/step - loss: 0.3953 - accuracy: 0.8273 - val_loss: 0.3317 - val_accuracy: 0.8601\u001b[0m92 - accuracy: 0.43\n",
      "\u001b[35m2023-10-30 17:46:54.637 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8573 - val_loss: 0.3284 - val_accuracy: 0.8620\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:46:55.582 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8650 - val_loss: 0.3255 - val_accuracy: 0.8675\u001b[0m - accuracy: 0.84\n",
      "\u001b[35m2023-10-30 17:46:56.516 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3188 - accuracy: 0.8684 - val_loss: 0.3242 - val_accuracy: 0.8606\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:46:57.481 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3093 - accuracy: 0.8729 - val_loss: 0.3236 - val_accuracy: 0.8642\u001b[0m - accuracy: 0.96\n",
      "\u001b[35m2023-10-30 17:46:58.422 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.3049 - accuracy: 0.8792 - val_loss: 0.3292 - val_accuracy: 0.8675\u001b[0m - accuracy: 1.00\n",
      "\u001b[35m2023-10-30 17:46:59.358 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2950 - accuracy: 0.8824 - val_loss: 0.3283 - val_accuracy: 0.8705\u001b[0m - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:47:00.311 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8886 - val_loss: 0.3344 - val_accuracy: 0.8645\u001b[0m - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:47:01.244 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8881 - val_loss: 0.3364 - val_accuracy: 0.8670\u001b[0m - accuracy: 0.96\n",
      "\u001b[35m2023-10-30 17:47:02.233 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "453/453 [==============================] - 1s 2ms/step - loss: 0.2737 - accuracy: 0.8954 - val_loss: 0.3454 - val_accuracy: 0.8659\u001b[0m - accuracy: 0.96\n",
      "\u001b[35m2023-10-30 17:47:03.256 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(22641,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:03.257 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mAbsolutely wonderful - silky and sexy and comfortable\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:04.592 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "566/566 [==============================] - 2s 3ms/step - loss: 0.3862 - accuracy: 0.8400 - val_loss: 0.3455 - val_accuracy: 0.8589\u001b[0m61 - accuracy: 0.75\n",
      "\u001b[35m2023-10-30 17:47:06.864 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3253 - accuracy: 0.8693 - val_loss: 0.3349 - val_accuracy: 0.8644\u001b[0m - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:47:08.251 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.3086 - accuracy: 0.8744 - val_loss: 0.3397 - val_accuracy: 0.8582\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:47:09.656 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2969 - accuracy: 0.8827 - val_loss: 0.3532 - val_accuracy: 0.8547\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:47:11.024 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2861 - accuracy: 0.8891 - val_loss: 0.3434 - val_accuracy: 0.8563\u001b[0m - accuracy: 0.87\n",
      "\u001b[35m2023-10-30 17:47:12.347 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.8899 - val_loss: 0.3549 - val_accuracy: 0.8527\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:47:13.685 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.8975 - val_loss: 0.3525 - val_accuracy: 0.8547\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:47:15.038 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2689 - accuracy: 0.9006 - val_loss: 0.3605 - val_accuracy: 0.8554\u001b[0m - accuracy: 0.90\n",
      "\u001b[35m2023-10-30 17:47:16.399 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2607 - accuracy: 0.9042 - val_loss: 0.3646 - val_accuracy: 0.8556\u001b[0m - accuracy: 1.00\n",
      "\u001b[35m2023-10-30 17:47:17.795 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 0.2546 - accuracy: 0.9073 - val_loss: 0.3737 - val_accuracy: 0.8541\u001b[0m - accuracy: 0.81\n",
      "\u001b[35m2023-10-30 17:47:19.180 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(4529,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:19.549 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mI received these pants today and they're perfect. as another reviewer stated, \"i would definitely not wear these for lounging\" you can dress them up or down. i feel like these will be my favorite go-to pants this spring. i highly recommend the design and pockets are perfect\u001b[0m\n",
      "142/142 [==============================] - 0s 985us/step\u001b[0m] \u001b[0m\u001b[22m1/142 [..............................] - ETA: 10\n",
      "\u001b[35m2023-10-30 17:47:19.741 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22m(4529,)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:20.046 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mI received these pants today and they're perfect. as another reviewer stated, \"i would definitely not wear these for lounging\" you can dress them up or down. i feel like these will be my favorite go-to pants this spring. i highly recommend the design and pockets are perfect\u001b[0m\n",
      "142/142 [==============================] - 0s 897us/step\u001b[0m] \u001b[0m\u001b[22m1/142 [..............................] - ETA: \n",
      "\u001b[35m2023-10-30 17:47:24.682 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:25.032 \u001b[0m\u001b[32m[9/model/72 (pid 9734)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:25.640 \u001b[0m\u001b[32m[9/aggregate/73 (pid 11336)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:29.785 \u001b[0m\u001b[32m[9/aggregate/73 (pid 11336)] \u001b[0m\u001b[22mModelResult(name='Baseline', params='Always predict 1', pathspec='BaselineChallenge/9/baseline/71', acc=0.7745639213954515, rocauc=0.5)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:29.853 \u001b[0m\u001b[32m[9/aggregate/73 (pid 11336)] \u001b[0m\u001b[22mModelResult(name='NbowModel - vocab_sz: 100', params={'vocab_sz': 100}, pathspec='BaselineChallenge/9/model/72', acc=0.833296533451093, rocauc=0.8565038691470007)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:29.853 \u001b[0m\u001b[32m[9/aggregate/73 (pid 11336)] \u001b[0m\u001b[22mModelResult(name='NbowModel - vocab_sz: 300', params={'vocab_sz': 300}, pathspec='BaselineChallenge/9/model/72', acc=0.8984323250165599, rocauc=0.9396380401533587)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:33.501 \u001b[0m\u001b[32m[9/aggregate/73 (pid 11336)] \u001b[0m\u001b[22mModelResult(name='NbowModel - vocab_sz: 500', params={'vocab_sz': 500}, pathspec='BaselineChallenge/9/model/72', acc=0.9194082578935747, rocauc=0.9605225833326819)\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:33.784 \u001b[0m\u001b[32m[9/aggregate/73 (pid 11336)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:34.215 \u001b[0m\u001b[32m[9/end/74 (pid 11418)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:37.224 \u001b[0m\u001b[32m[9/end/74 (pid 11418)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-10-30 17:47:37.368 \u001b[0m\u001b[1mDone! See the run in the UI at https://ui-pw-1791674716.outerbounds.dev/BaselineChallenge/9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python baseline_challenge.py run # --data '../data/Womens Clothing E-Commerce Reviews.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Exploring Advanced Visualization Opportunities with MF Cards (Optional)\n",
    "\n",
    "As ModaMetric continues to thrive and grow, it's clear that basic visualizations won't be enough to understand the intricate dynamics of our e-commerce customer sentiment. We want to take our data storytelling to the next level. And you, as a valued member of our data science team, are the perfect person to lead this initiative.\n",
    "\n",
    "This optional task is an open invitation for you to really explore how you can leverage Metaflow's features to deliver a compelling, multidimensional story.\n",
    "\n",
    "### Step 1: Dive Deeper into Hyperparameter Tuning Insights\n",
    "\n",
    "While we have already visualized the results of the hyperparameter tuning, we believe there's more to unearth. Consider how you might visualize the correlation between specific hyperparameters and model performance, or how different hyperparameter combinations affect the training time.\n",
    "\n",
    "### Step 2: Unearth Hidden Trends in Customer Sentiment\n",
    "\n",
    "ModaMetric prides itself on delivering the best for our customers. Can we use our sentiment analysis data to learn more about our customer preferences? Try to create visualizations that show trends in sentiment across different clothing categories, times of year, or any other dimension you find interesting.\n",
    "\n",
    "### Step 3: Explore Advanced Visualization Techniques\n",
    "\n",
    "Metaflow can accommodate a wide range of data visualization techniques. This is your chance to showcase those advanced skills. Perhaps you could experiment with multi-panel plots, 3D visualizations, or interactive plots that let viewers explore the data for themselves. You can refer to this [blog post](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjJwOe55pqAAxXA6KACHTZzAsoQFnoECCAQAQ&url=https%3A%2F%2Fouterbounds.com%2Fblog%2Fintegrating-pythonic-visual-reports-into-ml-pipelines%2F&usg=AOvVaw2PY3huULq5xR3yZEQ1s-OL&opi=89978449) for more information about how you may do this. \n",
    "\n",
    "We're looking forward to seeing where your creativity and technical expertise can lead ModaMetric. Remember, there are no boundaries - the sky's the limit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Full Stack ML Corise",
   "language": "python",
   "name": "full-stack-metaflow-corise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
